{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marvin/miniforge3/envs/cmpe/lib/python3.10/site-packages/bayesflow/trainers.py:27: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n",
      "INFO:root:Performing 2 pilot runs with the anonymous model...\n",
      "INFO:root:Shape of parameter batch after 2 pilot simulations: (batch_size = 2, 2)\n",
      "INFO:root:Shape of simulation batch after 2 pilot simulations: (batch_size = 2, 2)\n",
      "INFO:root:No optional prior non-batchable context provided.\n",
      "INFO:root:No optional prior batchable context provided.\n",
      "INFO:root:No optional simulation non-batchable context provided.\n",
      "INFO:root:No optional simulation batchable context provided.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import bayesflow as bf\n",
    "import tensorflow as tf\n",
    "from sc_abi.sc_amortizers import AmortizedPosteriorLikelihoodSC\n",
    "from sc_abi.sc_schedules import ZeroOneSchedule\n",
    "from tasks.two_moons import generative_model, prior, get_amortizer_arguments\n",
    "\n",
    "from tasks.two_moons import analytic_posterior_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_budgets = 512, 1024, 2048, 4096\n",
    "run_id = 1\n",
    "TASK_NAME = \"two_moons\"\n",
    "\n",
    "os.makedirs(f'./computations/{TASK_NAME}', exist_ok=True)\n",
    "PLOT_DIR = Path(\"plots\", TASK_NAME)\n",
    "CHECKPOINT_DIR = Path(\"checkpoints/\", TASK_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trainers(budget):\n",
    "    trainer_nple = bf.trainers.Trainer(\n",
    "            amortizer=bf.amortizers.AmortizedPosteriorLikelihood(**get_amortizer_arguments()),\n",
    "            generative_model=generative_model,\n",
    "            default_lr=5e-4,\n",
    "            memory=False,\n",
    "            checkpoint_path=CHECKPOINT_DIR / str(budget) / \"nple\" / str(run_id),\n",
    "            configurator=bf.benchmarks.Benchmark('two_moons', 'joint').configurator,\n",
    "            max_to_keep=1,\n",
    "        )\n",
    "\n",
    "\n",
    "    # SC-ABI trainer\n",
    "    lambda_scheduler = ZeroOneSchedule(threshold_step=32*100)\n",
    "    trainer_sc10 = bf.trainers.Trainer(\n",
    "        amortizer=AmortizedPosteriorLikelihoodSC(\n",
    "            **get_amortizer_arguments(),\n",
    "            prior=prior,\n",
    "            n_consistency_samples=10,\n",
    "            lambda_schedule=lambda_scheduler,\n",
    "            theta_clip_value_min=-2.0,\n",
    "            theta_clip_value_max=2.0 - 1e-5, # uniform distribution excludes upper limit\n",
    "            ),\n",
    "        generative_model=generative_model,\n",
    "        default_lr=5e-4,\n",
    "        memory=False,\n",
    "        checkpoint_path=CHECKPOINT_DIR / str(budget) / \"sc\" / str(run_id),\n",
    "        configurator=bf.benchmarks.Benchmark('two_moons', 'joint').configurator,\n",
    "        max_to_keep=1,\n",
    "    )\n",
    "    return trainer_nple, trainer_sc10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_eval = 1000\n",
    "n_draws = 1000\n",
    "\n",
    "eval_data = generative_model(n_eval)\n",
    "\n",
    "names = ['NPLE', 'SC-NPLE']\n",
    "likelihood_estimates = {name: {budget: {'samples': None} for budget in simulation_budgets} for name in names}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Performing 2 pilot runs with the two_moons model...\n",
      "INFO:root:Shape of parameter batch after 2 pilot simulations: (batch_size = 2, 2)\n",
      "INFO:root:Shape of simulation batch after 2 pilot simulations: (batch_size = 2, 2)\n",
      "INFO:root:No optional prior non-batchable context provided.\n",
      "INFO:root:No optional prior batchable context provided.\n",
      "INFO:root:No optional simulation non-batchable context provided.\n",
      "INFO:root:No optional simulation batchable context provided.\n",
      "INFO:root:Loaded loss history from checkpoints/two_moons/512/nple/1/history_201.pkl.\n",
      "INFO:root:Networks loaded from checkpoints/two_moons/512/nple/1/ckpt-201\n",
      "INFO:root:Performing a consistency check with provided components...\n",
      "INFO:root:Done.\n",
      "INFO:root:Performing 2 pilot runs with the two_moons model...\n",
      "INFO:root:Shape of parameter batch after 2 pilot simulations: (batch_size = 2, 2)\n",
      "INFO:root:Shape of simulation batch after 2 pilot simulations: (batch_size = 2, 2)\n",
      "INFO:root:No optional prior non-batchable context provided.\n",
      "INFO:root:No optional prior batchable context provided.\n",
      "INFO:root:No optional simulation non-batchable context provided.\n",
      "INFO:root:No optional simulation batchable context provided.\n",
      "INFO:root:Loaded loss history from checkpoints/two_moons/512/sc/1/history_201.pkl.\n",
      "INFO:root:Networks loaded from checkpoints/two_moons/512/sc/1/ckpt-201\n",
      "INFO:root:Performing a consistency check with provided components...\n",
      "INFO:root:Done.\n",
      "INFO:root:Performing 2 pilot runs with the two_moons model...\n",
      "INFO:root:Shape of parameter batch after 2 pilot simulations: (batch_size = 2, 2)\n",
      "INFO:root:Shape of simulation batch after 2 pilot simulations: (batch_size = 2, 2)\n",
      "INFO:root:No optional prior non-batchable context provided.\n",
      "INFO:root:No optional prior batchable context provided.\n",
      "INFO:root:No optional simulation non-batchable context provided.\n",
      "INFO:root:No optional simulation batchable context provided.\n",
      "INFO:root:Loaded loss history from checkpoints/two_moons/1024/nple/1/history_201.pkl.\n",
      "INFO:root:Networks loaded from checkpoints/two_moons/1024/nple/1/ckpt-201\n",
      "INFO:root:Performing a consistency check with provided components...\n",
      "INFO:root:Done.\n",
      "INFO:root:Performing 2 pilot runs with the two_moons model...\n",
      "INFO:root:Shape of parameter batch after 2 pilot simulations: (batch_size = 2, 2)\n",
      "INFO:root:Shape of simulation batch after 2 pilot simulations: (batch_size = 2, 2)\n",
      "INFO:root:No optional prior non-batchable context provided.\n",
      "INFO:root:No optional prior batchable context provided.\n",
      "INFO:root:No optional simulation non-batchable context provided.\n",
      "INFO:root:No optional simulation batchable context provided.\n",
      "INFO:root:Loaded loss history from checkpoints/two_moons/1024/sc/1/history_201.pkl.\n",
      "INFO:root:Networks loaded from checkpoints/two_moons/1024/sc/1/ckpt-201\n",
      "INFO:root:Performing a consistency check with provided components...\n",
      "INFO:root:Done.\n",
      "INFO:root:Performing 2 pilot runs with the two_moons model...\n",
      "INFO:root:Shape of parameter batch after 2 pilot simulations: (batch_size = 2, 2)\n",
      "INFO:root:Shape of simulation batch after 2 pilot simulations: (batch_size = 2, 2)\n",
      "INFO:root:No optional prior non-batchable context provided.\n",
      "INFO:root:No optional prior batchable context provided.\n",
      "INFO:root:No optional simulation non-batchable context provided.\n",
      "INFO:root:No optional simulation batchable context provided.\n",
      "INFO:root:Loaded loss history from checkpoints/two_moons/2048/nple/1/history_201.pkl.\n",
      "INFO:root:Networks loaded from checkpoints/two_moons/2048/nple/1/ckpt-201\n",
      "INFO:root:Performing a consistency check with provided components...\n",
      "INFO:root:Done.\n",
      "INFO:root:Performing 2 pilot runs with the two_moons model...\n",
      "INFO:root:Shape of parameter batch after 2 pilot simulations: (batch_size = 2, 2)\n",
      "INFO:root:Shape of simulation batch after 2 pilot simulations: (batch_size = 2, 2)\n",
      "INFO:root:No optional prior non-batchable context provided.\n",
      "INFO:root:No optional prior batchable context provided.\n",
      "INFO:root:No optional simulation non-batchable context provided.\n",
      "INFO:root:No optional simulation batchable context provided.\n",
      "INFO:root:Loaded loss history from checkpoints/two_moons/2048/sc/1/history_201.pkl.\n",
      "INFO:root:Networks loaded from checkpoints/two_moons/2048/sc/1/ckpt-201\n",
      "INFO:root:Performing a consistency check with provided components...\n",
      "INFO:root:Done.\n",
      "INFO:root:Performing 2 pilot runs with the two_moons model...\n",
      "INFO:root:Shape of parameter batch after 2 pilot simulations: (batch_size = 2, 2)\n",
      "INFO:root:Shape of simulation batch after 2 pilot simulations: (batch_size = 2, 2)\n",
      "INFO:root:No optional prior non-batchable context provided.\n",
      "INFO:root:No optional prior batchable context provided.\n",
      "INFO:root:No optional simulation non-batchable context provided.\n",
      "INFO:root:No optional simulation batchable context provided.\n",
      "INFO:root:Loaded loss history from checkpoints/two_moons/4096/nple/1/history_201.pkl.\n",
      "INFO:root:Networks loaded from checkpoints/two_moons/4096/nple/1/ckpt-201\n",
      "INFO:root:Performing a consistency check with provided components...\n",
      "INFO:root:Done.\n",
      "INFO:root:Performing 2 pilot runs with the two_moons model...\n",
      "INFO:root:Shape of parameter batch after 2 pilot simulations: (batch_size = 2, 2)\n",
      "INFO:root:Shape of simulation batch after 2 pilot simulations: (batch_size = 2, 2)\n",
      "INFO:root:No optional prior non-batchable context provided.\n",
      "INFO:root:No optional prior batchable context provided.\n",
      "INFO:root:No optional simulation non-batchable context provided.\n",
      "INFO:root:No optional simulation batchable context provided.\n",
      "INFO:root:Loaded loss history from checkpoints/two_moons/4096/sc/1/history_201.pkl.\n",
      "INFO:root:Networks loaded from checkpoints/two_moons/4096/sc/1/ckpt-201\n",
      "INFO:root:Performing a consistency check with provided components...\n",
      "INFO:root:Done.\n"
     ]
    }
   ],
   "source": [
    "logml_dict = {name: {budget: {'logml': None} for budget in simulation_budgets} for name in names}\n",
    "\n",
    "for budget in simulation_budgets:\n",
    "    trainer_nple, trainer_sc10 = load_trainers(budget)\n",
    "    for name, trainer in zip(names, [trainer_nple, trainer_sc10]):\n",
    "        n_eval = eval_data['prior_draws'].shape[0]\n",
    "        logml = np.zeros((n_eval, n_draws), dtype=np.float32)\n",
    "        eval_data_config = trainer.configurator(eval_data)\n",
    "        theta_est = trainer.amortizer.sample_parameters(eval_data_config, n_samples=n_draws)\n",
    "\n",
    "\n",
    "        for i in range(n_draws):\n",
    "            est_dict = {\n",
    "                'posterior_inputs': {'direct_conditions': eval_data['sim_data'], 'parameters': theta_est[:, i, :]},\n",
    "                'likelihood_inputs': {'conditions': theta_est[:, i, :], 'observables': eval_data['sim_data']}\n",
    "            }\n",
    "            log_prior = np.array(prior.log_prob(theta_est[:, i, :]))\n",
    "            log_likelihood = np.array(trainer.amortizer.log_likelihood(est_dict))\n",
    "            log_posterior = np.array(trainer.amortizer.log_posterior(est_dict))\n",
    "\n",
    "            logml[:, i] = log_prior + log_likelihood - log_posterior\n",
    "        logml_dict[name][budget]['logml'] = logml\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPLE & $6.51 {\\pm} 0.11$ & $7.28 {\\pm} 0.10$ & $9.07 {\\pm} 0.06$ & $10.21 {\\pm} 0.08$\\\\\n",
      "SC-NPLE & $1.70 {\\pm} 0.02$ & $1.37 {\\pm} 0.02$ & $1.21 {\\pm} 0.01$ & $1.14 {\\pm} 0.01$\\\\\n"
     ]
    }
   ],
   "source": [
    "for name in names:\n",
    "    print(fr'{name}', end=\"\")\n",
    "    for budget in simulation_budgets:\n",
    "        logml = logml_dict[name][budget]['logml']\n",
    "        # turn -inf to nan\n",
    "        logml[logml == -np.inf] = np.nan\n",
    "        lower_ci = np.nanpercentile(logml, 2.5, axis=1, )\n",
    "        upper_ci = np.nanpercentile(logml, 97.5, axis=1)\n",
    "        sharpness = upper_ci - lower_ci\n",
    "\n",
    "        # sharpness_median = np.median(sharpness)\n",
    "        # sharpness_lower = np.percentile(sharpness, 2.5)\n",
    "        # sharpness_upper = np.percentile(sharpness, 97.5)\n",
    "        sharpness_mean = np.mean(sharpness)\n",
    "        sharpness_se = np.std(sharpness) / np.sqrt(sharpness.shape[0])\n",
    "        print(rf' & ${sharpness_mean:.2f} {{\\pm}} {sharpness_se:.2f}$', end=\"\")\n",
    "        \n",
    "        \n",
    "    # print(r'\\\\')\n",
    "    # for budget in simulation_budgets:\n",
    "    #     logml = logml_dict[name][budget]['logml']\n",
    "    #     logml[logml == -np.inf] = np.nan\n",
    "    #     lower_ci = np.nanpercentile(logml, 2.5, axis=1)\n",
    "    #     upper_ci = np.nanpercentile(logml, 97.5, axis=1)\n",
    "    #     sharpness = upper_ci - lower_ci\n",
    "\n",
    "    #     sharpness_median = np.median(sharpness)\n",
    "    #     sharpness_lower = np.percentile(sharpness, 2.5)\n",
    "    #     sharpness_upper = np.percentile(sharpness, 97.5)\n",
    "        \n",
    "    #     print(rf' &\\scriptsize\\scriptsize\\raisebox{{0.10cm}}{{[{sharpness_lower:.2f}, {sharpness_upper:.2f}]}}', end=\"\")\n",
    "    print(r'\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmpe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
